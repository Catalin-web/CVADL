{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJnU5vvafZQD"
      },
      "source": [
        "# Convolutional Neural Networks in pytorch\n",
        "\n",
        "The main pipeline when training a neural network model is:\n",
        "5. Test and *analyze* the results.\n",
        "*Repeat the steps 2-5*\n",
        "\n",
        "\n",
        "# 1. Datasets and data loaders\n",
        "\n",
        "``torch.utils.data.Dataset`` stores the actual information about the dataset (the samples and their corresponding ground truth labels), while the torch.``utils.data.DataLoader`` wraps an iterable around the dataset, allowing easy access to the data, automatic batching, and multi-process data loading).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zV9pXMPGIzcT"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# 2. The Convolutional Neural Network\n",
        "\n",
        "## Convolutional Neural Networks for scratch\n",
        "\n",
        "Check the tutorial from reference [[2]](#scrollTo=my1Fk-G5KKmz&line=2&uniqifier=1).\n",
        "\n",
        "You'll define your convolutional neural network by extending the [torch.nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) class, which is the base class for all the neural network modules.\n",
        "In the constructor, you define the layers (and their properties) that comprise your module. ``torch.nn`` [package](https://pytorch.org/docs/stable/nn.html) provides classes for the basic layers of a CNN.\n",
        "\n",
        "The function that you need to override is the _forward()_ function in which you specify computation performed at every call (i.e. how are layers chained and how does the data flow over the computational graph). In other words, this defines the forward pass through your model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azt4BFMlI2zb"
      },
      "outputs": [],
      "source": [
        "# TODO your code here: define a simple CNN model, pass a single example through the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqXebwmRI6p7"
      },
      "source": [
        "## Transfer learning\n",
        "\n",
        "\n",
        "Check the tutorial from reference [[3]](#scrollTo=my1Fk-G5KKmz&line=2&uniqifier=1).\n",
        "\n",
        "\n",
        "The ``torchvision`` module provides the implementation and pre-trained weights for common neural network architectures.\n",
        "For example, to load the resnet18 architecture and its weights (after training on ImageNet, you can use:\n",
        "\n",
        "\n",
        "```[python]\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "\n",
        "# Using pretrained weights:\n",
        "model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "```\n",
        "\n",
        " Remember from the first lab, that when using a pre-trained model you must preprocess to the image as the images used for training the model. Using the correct preprocessing method is critical and failing to do so may lead to decreased accuracy or incorrect outputs. Each architecture uses a different preprocessing technique, so there is no standard way to achieve this.\n",
        "\n",
        "\n",
        "#### Note (transfer learning training)\n",
        " In the tutorial, you will notice that the authors use model.train() and model.eval() in the training loop. These functions \"tell\" the model how to act when it is being run. In the next lectures, you will learn that some layers (such as dropout, batch normalization, and so on) behave differently during train and evaluation, and hence the model will produce unexpected results if run in the wrong mode. So don't forget these steps.\n",
        "\n",
        "\n",
        " To freeze the weights of the model and train only the rest, you can set requires_grad of the parameters you want to freeze to False.\n",
        "```\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "```\n",
        "\n",
        "\n",
        "On the other hand, the ``torch.no_grad()``context manager that we used in the prvious lab  is used to prevent calculating gradients in the following code block. Usually it is used when you evaluate your model and don’t need to call backward() to calculate the gradients and update the corresponding parameters. In this mode, the result of every computation will have ``requires_grad=False``, even when the inputs have ``requires_grad=True``.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DW7VW3NNJxD7"
      },
      "outputs": [],
      "source": [
        "# TODO : your code here\n",
        "# get a pretrained torchvision module, change the last layer,  pass a single example through the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SgWnQCfI3Bz"
      },
      "source": [
        "# 3. Training the model\n",
        "\n",
        "\n",
        "For training, we need to define a loss function and an optimizer. We'll cover optimizers next time, in this laboratory we'll just stick to stochastic gradient descent.\n",
        "\n",
        "\n",
        "Let's first define some concepts:\n",
        "- epoch: an epoch defines a pass through the entire training dataset. The number of epochs (passes of the entire training dataset the machine learning algorithm has completed) is a hyperparameter of your model. An epoch consists of one or more batches.\n",
        "- batch:  a batch defines how many samples your model \"sees\" before updating its weights. In other words, the batch size is the number of samples that will be passed through to the network at one time during its training.\n",
        "- sample: a sample is just a single training example.\n",
        "\n",
        "\n",
        "As you saw in the previous laboratory, a typical training loop looks like this:\n",
        "```\n",
        "\n",
        "\n",
        "optimizer - the chosen optimizer. It holds the current state of the model and will update the parameters based on the computed gradients. Notice that in the constructor of the optimizer you need to pass the parameters of your model and the learning rate.\n",
        "criterion - the chosen loss function.\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):  # num_epochs is a hyperparameter that specifies when is the training process\n",
        "\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(dataloader, 0): # iterate over the dataset, now we use data loaders\n",
        "        # get a batch of data (inputs and their corresponding labels)\n",
        "        inputs, labels = data\n",
        "\n",
        "\n",
        "        # IMPORTANT! set the gradients of the tensors to 0. by default torch accumulates the gradients on subsequent backward passes\n",
        "        # if you omit this step, the gradient would be a combination of the old gradient, which you have already used to update the parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "\n",
        "        # perform the forward pass through the network\n",
        "        outputs = net(inputs)\n",
        "       \n",
        "        # apply the loss function to determine how your model performed on this batch\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # start the backprop process. it will compute the gradient of the loss with respect to the graph leaves\n",
        "        loss.backward()\n",
        "\n",
        "\n",
        "        # update the model parameters by calling the step function\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjlfH7uEI9nL"
      },
      "outputs": [],
      "source": [
        "# TODO code to train your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FjwKf-oJ62y"
      },
      "outputs": [],
      "source": [
        "# TODO code to train your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yBZGbkx1kQX"
      },
      "source": [
        "\n",
        "\n",
        "Now let's examine the effect of the learning rate over the training process.\n",
        "\n",
        "- First, create two plots: one in which you plot, for each epoch, the loss values on the training and the test data (two series on the same graph), and another one in which you plot, for each epoch, the accuracy values on the training and the test data.\n",
        "- Experiment with different values for the learning rate.\n",
        "- Then, experiment with a torch.optim.lr_scheduler to adjust the learning rate during the training process [doc](!https://pytorch.org/docs/stable/optim.html).\n",
        "\n",
        "```\n",
        "optimizer = SGD(model, lr)\n",
        "scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for input, target in dataset:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(input)\n",
        "        loss = loss_fn(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    # apply the learning rate scheduler\n",
        "    scheduler.step()\n",
        "```\n",
        "\n",
        "Plot the learning curves for all the training that you performed.\n",
        "Fill in the table to compare the accuracy of your trained models.\n",
        "\n",
        "| Model              | lr config            | accuracy  train| accuracy test |\n",
        "| -----------        | -----------          | ------         | -----         |\n",
        "| Model              | lr info              |   acc          |acc            |\n",
        "| Model              | lr info              |   acc          |acc            |\n",
        "\n",
        "\n",
        "You can work in teams and each team will train the model with a different setup.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uycj0PIUMc2_"
      },
      "source": [
        "# Using the GPU\n",
        "\n",
        "``torch`` is designed to allow for computation both on CPU and on GPU.\n",
        "If your system has a GPU and the required libraries configured for torch compatibility, the cell below will print information about its state.\n",
        "\n",
        "If you are running your code on colab, you can enable GPU computation from: Runtime->Change Runtime type -> T4 GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WI_K2aWkMaaY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    !nvidia-smi\n",
        "else:\n",
        "    print(\"NO GPU ☹️\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSSXI-3iNc7e"
      },
      "source": [
        "Now we can start to use accelaration.\n",
        "You now need to explictly specify on which device your tensors reside. You can\n",
        "move all of the model's parameters `.to` a certain device (the GPU)\n",
        "and also move the data on the same device there as well\n",
        "before applying the model and calculating the loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwlrUVINOWLu"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model.to(device)\n",
        "loss_fn(model(x.to(device)), y.to(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my1Fk-G5KKmz"
      },
      "source": [
        "#Useful references\n",
        "\n",
        "- [1] [a \"recipe\" ](http://karpathy.github.io/2019/04/25/recipe/)  when you will start training artifcial neural networks;\n",
        "- [2] [Defining a CNN](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html) in torch;\n",
        "- [3] [Transfer learning](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html) in torch;\n",
        "- [4] [model debugging](https://developers.google.com/machine-learning/testing-debugging/common/overview)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heKTIeINgByi"
      },
      "source": [
        "# <font color='red'> Optional </font>  \n",
        "## Pooling\n",
        "\n",
        "The pooling layer is used to reduce the spatial dimension of the activation maps, and thus the computational burden. It has no learnable parameters and it operates individually across each input channel and resizes it spatially.\n",
        "\n",
        "The two most common types of pooling are max pooling and average pooling.\n",
        "\n",
        "\n",
        "The hyperparameters of a pooling layer are:\n",
        "- the filter size F (usually this is an odd value);\n",
        "- the stride S (or the step used when sliding across the input volume);\n",
        "\n",
        "Given an input volume of shape  ($H_i$, $W_i$, $D$), the convolutional layer will produce an output of shape ($H_o$, $W_o$, $D$), where:\n",
        "\n",
        "\\begin{equation}\n",
        "W_o = \\frac{W_i - F}{S} + 1\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "H_o = \\frac{H_i - F}{S} + 1\n",
        "\\end{equation}\n",
        "\n",
        "An illustration of the pooling operation is depicted in the image below:\n",
        "\n",
        "![picture](https://www.researchgate.net/profile/Alla-Eddine-Guissous/publication/337336341/figure/fig15/AS:855841334898691@1581059883782/Example-for-the-max-pooling-and-the-average-pooling-with-a-filter-size-of-22-and-a.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t81pBIwF5lzv"
      },
      "outputs": [],
      "source": [
        "def pooling(X, filter_size, stride, type):\n",
        "     \"\"\"\n",
        "    Implements the pooling operation\n",
        "\n",
        "    :param X - input volume of shape (num_samples, H, W, C)\n",
        "    :param filter_size - the size of the pooling\n",
        "    :param stride - the stride of the pooling operation\n",
        "    :param type - can be 'max' or 'avg'; the type of the pooling operation to apply\n",
        "\n",
        "    Returns the output of the pooling operation.\n",
        "    \"\"\"\n",
        "  # TODO your code here implement the pooling operation\n",
        "  # you can inspire yourself from the convolution implementation on how to organize your code\n",
        "  pass\n",
        "\n",
        "# TODO your code here\n",
        "# apply the pooling operation on a grayscale image and on a color image\n",
        "# try different values for the stride and filter size. What do you observe?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
